# 🧠 Virtual Assistant for Blind Users

This Android app uses object detection and voice interaction to assist visually impaired users with their surroundings.

## 📸 Screenshots

### Interface
<img src="https://github.com/user-attachments/assets/9ad49392-f159-4c11-90ed-a2b07d071e5b" width="350" height = "600"/>
<img src="https://github.com/user-attachments/assets/72064561-e933-4878-9812-ff16c4d389fb" width="350" height = "600"/>

### Hardware Prototype
<img src="https://github.com/user-attachments/assets/9b64f5fa-5e5a-46bd-9dc6-55a26780fb4b" width="350" height = "600"/>

### 🔍 Object Detection
<img src="https://github.com/user-attachments/assets/3a9a72df-1f90-4767-a61c-cf2015336d8d" width="350" height = "600"/>

### 🗣️ Voice Commands
<img src="https://github.com/user-attachments/assets/b71432d8-122a-4000-9e6a-86471b658031" width="350" height = "600"/>
<img src="https://github.com/user-attachments/assets/c86f009e-9d7a-4b1e-a815-61793e43479d" width="350" height = "600"/>

## 🧰 Tech Stack
- Kotlin + Jetpack Compose
- CameraX + Google ML Kit (https://developers.google.com/ml-kit)
- Text-to-Speech, Gmail API
- `mobile_object_labeler_v1` TFLite Model (https://www.kaggle.com/models/google/mobile-object-labeler-v1)
